{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import chardet\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 原始数据目录\n",
    "folder_path = './J'\n",
    "# csv文件目录\n",
    "csv_path = './csv'\n",
    "#excel文件目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.一级目录转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功提取 687 项\n"
     ]
    }
   ],
   "source": [
    "# 初始化一个空的DataFrame来存储结果\n",
    "results = pd.DataFrame(columns=[\n",
    "    'id', 'Type', 'Dates', 'Observatory', \n",
    "    'Reference Frame', 'Centre of Frame', 'Epoch of Equinox', \n",
    "    'Time Scale', 'Reduction', 'Coordinates', 'Diffraction', 'Receptor', \n",
    "    'Telescope', 'Observers'\n",
    "])\n",
    "\n",
    "# 初始化字典来记录成功和失败的项\n",
    "status = {\n",
    "    'success': [],\n",
    "    'failures': {}\n",
    "}\n",
    "\n",
    "# 遍历文件夹内的所有HTML文件\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.html'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        file_id = os.path.splitext(filename)[0]  # 获取不包含后缀的文件名\n",
    "        \n",
    "        # 检测文件编码\n",
    "        with open(file_path, 'rb') as file:\n",
    "            raw_data = file.read()\n",
    "            result = chardet.detect(raw_data)\n",
    "            encoding = result['encoding']\n",
    "\n",
    "        # 读取文件内容\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            html_content = file.read()\n",
    "        \n",
    "        # 初始化一个字典来存储当前文件的结果\n",
    "        current_file_results = {'id': file_id}\n",
    "        \n",
    "        # 使用正则表达式提取Contents.部分的type, dates, observatory\n",
    "        contents_patterns = {\n",
    "            'Type': r'\\btype:\\s*(.+)',\n",
    "            'Dates': r'\\bdates:\\s*(.+)',\n",
    "            'Observatory': r'\\bobservatory:\\s*(.+)'\n",
    "        }\n",
    "        \n",
    "        # 提取Contents.部分的内容\n",
    "        for key, pattern in contents_patterns.items():\n",
    "            regex = re.compile(pattern)\n",
    "            match = regex.search(html_content)\n",
    "            if match:\n",
    "                current_file_results[key] = match.group(1).strip()\n",
    "                status['success'].append(filename)\n",
    "            else:\n",
    "                if filename not in status['failures']:\n",
    "                    status['failures'][filename] = []\n",
    "                status['failures'][filename].append(key)\n",
    "        \n",
    "        # 提取Informations.到Comments.或Format.之间的全部内容\n",
    "        informations_pattern = r'Informations\\..*?(?=\\b(Comments|Format)\\.)'\n",
    "        informations_match = re.search(informations_pattern, html_content, re.DOTALL)\n",
    "        if informations_match:\n",
    "            informations_content = informations_match.group(0).strip()\n",
    "            \n",
    "            # 提取Informations.部分的各个字段\n",
    "            fields_patterns = {\n",
    "                'Reference Frame': r'\\breference frame:\\s*(.+)',\n",
    "                'Centre of Frame': r'\\bcentre of frame:\\s*(.+)',\n",
    "                'Epoch of Equinox': r'\\bepoch of equinox:\\s*(.+)',\n",
    "                'Time Scale': r'\\btime scale:\\s*(.+)',\n",
    "                'Reduction': r'\\breduction:\\s*(.+)',\n",
    "                'Coordinates': r'\\bcoordinates:\\s*(.+)',\n",
    "                'Diffraction': r'\\bdiff. refraction:\\s*(.+)',\n",
    "                'Receptor': r'\\breceptor:\\s*(.+)',\n",
    "                'Telescope': r'\\btelescope:\\s*(.+)',\n",
    "                'Observers': r'\\bobservers:\\s*(.+)'\n",
    "            }\n",
    "            \n",
    "            for field, pattern in fields_patterns.items():\n",
    "                regex = re.compile(pattern)\n",
    "                match = regex.search(informations_content)\n",
    "                if match:\n",
    "                    current_file_results[field] = match.group(1).strip()\n",
    "                else:\n",
    "                    current_file_results[field] = None  # 如果字段不存在，则设为None\n",
    "            \n",
    "            # 处理可能有多个relative to的情况\n",
    "            relative_pattern = r'\\brelative to:\\s*(.+)'\n",
    "            relative_matches = re.findall(relative_pattern, informations_content)\n",
    "            if relative_matches:\n",
    "                current_file_results['Relative To'] = '; '.join(relative_matches)\n",
    "        \n",
    "        else:\n",
    "            if filename not in status['failures']:\n",
    "                status['failures'][filename] = []\n",
    "            status['failures'][filename].append('Informations')\n",
    "        \n",
    "        # 将提取的内容添加到DataFrame中\n",
    "        results = results.append(current_file_results, ignore_index=True)\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "results.to_csv('Informations.csv', index=False)\n",
    "\n",
    "# 打印成功和失败的项\n",
    "print(f\"成功提取 {len(status['success'])} 项\")\n",
    "if status['failures']:\n",
    "    print(\"失败的项有：\")\n",
    "    for filename, missing_keys in status['failures'].items():\n",
    "        print(f\"文件 {filename} 缺失以下信息：{', '.join(missing_keys)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 坐标系统格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取CSV文件\n",
    "df = pd.read_csv('Informations.csv')\n",
    "\n",
    "# 检查'Epoch of Equinox'列是否存在\n",
    "if 'Epoch of Equinox' in df.columns:\n",
    "    # 获取'Epoch of Equinox'列的所有值\n",
    "    time_scale_values = df['Epoch of Equinox'].unique()\n",
    "    \n",
    "    # 将所有值连接成一个字符串，每个值占一行\n",
    "    values_as_string = '\\n'.join(time_scale_values)\n",
    "    \n",
    "    print(\"'Epoch of Equinox'列的所有值：\")\n",
    "    print(values_as_string + '\\n')\n",
    "else:\n",
    "    print(\"CSV文件中没有找到'Epoch of Equinox'列。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时间系统格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取CSV文件\n",
    "df = pd.read_csv('Informations.csv')\n",
    "\n",
    "# 检查'Time Scale'列是否存在\n",
    "if 'Time Scale' in df.columns:\n",
    "    # 获取'Time Scale'列的所有值\n",
    "    time_scale_values = df['Time Scale'].unique()\n",
    "    \n",
    "    # 将所有值连接成一个字符串，每个值占一行\n",
    "    values_as_string = '\\n'.join(time_scale_values)\n",
    "    \n",
    "    print(\"'Time Scale'列的所有值：\")\n",
    "    print(values_as_string + '\\n')\n",
    "else:\n",
    "    print(\"CSV文件中没有找到'Time Scale'列。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.二级目录转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TXT观测数据转成成CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TXT files: 100%|██████████| 229/229 [00:00<00:00, 276.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files were converted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 确保CSV目录存在\n",
    "if not os.path.exists(csv_path):\n",
    "    os.makedirs(csv_path)\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return chardet.detect(file.read())['encoding']\n",
    "\n",
    "def detect_delimiter(file_content):\n",
    "    # 尝试识别常见的分隔符\n",
    "    patterns = {\n",
    "        ',': re.compile(r'[^,]+'),\n",
    "        '\\t': re.compile(r'[^\\t]+'),\n",
    "        ' ': re.compile(r'[^\\s]+')\n",
    "    }\n",
    "    max_match_count = 0\n",
    "    detected_delimiter = None\n",
    "    for delimiter, pattern in patterns.items():\n",
    "        matches = len(pattern.findall(file_content))\n",
    "        if matches > max_match_count:\n",
    "            max_match_count = matches\n",
    "            detected_delimiter = delimiter\n",
    "    return detected_delimiter\n",
    "\n",
    "# 记录失败的项目\n",
    "failed_files = []\n",
    "\n",
    "# 遍历文件夹中的所有TXT文件\n",
    "txt_files = [f for f in os.listdir(folder_path) if f.endswith(\".txt\")]\n",
    "for filename in tqdm(txt_files, desc='Processing TXT files'):\n",
    "    # 构建完整的文件路径\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # 检测文件编码\n",
    "    encoding = detect_encoding(file_path)\n",
    "    \n",
    "    # 读取TXT文件内容\n",
    "    with open(file_path, 'r', encoding=encoding, errors='ignore') as file:\n",
    "        file_content = file.read()\n",
    "        \n",
    "        # 检测分隔符\n",
    "        delimiter = detect_delimiter(file_content)\n",
    "        if delimiter is None:\n",
    "            failed_files.append(filename)\n",
    "            continue\n",
    "        \n",
    "        # 分割数据，忽略多余的空格\n",
    "        lines = file_content.split('\\n')\n",
    "        csv_lines = []\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip():  # 忽略空行\n",
    "                if delimiter == '\\t':  # 处理制表符分隔的数据\n",
    "                    fields = line.split('\\t')\n",
    "                elif delimiter == ' ':  # 处理空格分隔的数据\n",
    "                    fields = line.split()\n",
    "                else:  # 处理逗号分隔的数据\n",
    "                    fields = line.split(',')\n",
    "                # 在每个字段后面加上]\n",
    "                fields_with_brackets = [field + ']' for field in fields]\n",
    "                csv_lines.append(fields_with_brackets)\n",
    "        \n",
    "        # 构建CSV文件的完整路径\n",
    "        csv_filename = filename.replace('.txt', '.csv')\n",
    "        csv_file_path = os.path.join(csv_path, csv_filename)\n",
    "        \n",
    "        # 将内容写入CSV文件\n",
    "        try:\n",
    "            with open(csv_file_path, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "                csv_writer = csv.writer(csv_file)\n",
    "                \n",
    "                # 写入表头\n",
    "                headers = [f\"C{i+1}\" for i in range(len(csv_lines[0]))]\n",
    "                csv_writer.writerow(headers)\n",
    "                \n",
    "                # 写入数据\n",
    "                for row in csv_lines:\n",
    "                    csv_writer.writerow(row)\n",
    "        except Exception as e:\n",
    "            failed_files.append(filename)\n",
    "            print(f\"Failed to write {filename}: {e}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(\"Failed to convert files:\", failed_files)\n",
    "else:\n",
    "    print(\"All files were converted successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取各目录列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4860d70b4374>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 遍历文件夹中的所有CSV文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcsv_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsv_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# 存储CSV文件名和列数的列表\n",
    "csv_info = []\n",
    "\n",
    "# 遍历文件夹中的所有CSV文件\n",
    "csv_files = [f for f in os.listdir(csv_path) if f.endswith(\".csv\")]\n",
    "\n",
    "for filename in csv_files:\n",
    "    file_path = os.path.join(csv_path, filename)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            # 尝试获取第一行数据来确定列数\n",
    "            first_row = next(csv_reader)\n",
    "            num_columns = len(first_row)\n",
    "            csv_info.append([(filename.split(\".\"))[0], num_columns])\n",
    "    except Exception as e:\n",
    "        print (f\"Failed to read {filename}: {e}\")\n",
    "\n",
    "# 将结果写入到输出CSV文件\n",
    "try:\n",
    "    with open('column_info.csv', 'w', encoding='utf-8', newline='') as output_file:\n",
    "        writer = csv.writer(output_file)\n",
    "        writer.writerow(['Filename', 'Number of Columns'])  # 写入表头\n",
    "        for info in csv_info:\n",
    "            writer.writerow(info)\n",
    "    print(f\"Column information has been written to column_info.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to write to column_info.csv: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.三级数据整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
